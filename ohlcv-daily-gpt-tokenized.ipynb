{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10887013,"sourceType":"datasetVersion","datasetId":6765132}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Stock GPT\n- Have used to train both forward gpt, backward gpt and daily gpt models.\n- Using etf_data_parallel_gpt because it is the most recent codebase.(renamed to motnh-gpt-usethis)\n- Training a bigger model because the errors are saturated very easily.\n- Running this notebook for ohlcv_data\n  ","metadata":{}},{"cell_type":"markdown","source":"## Step 1 : Import all essentials, make sure they are right","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T18:04:09.413401Z","iopub.execute_input":"2025-04-05T18:04:09.413687Z","iopub.status.idle":"2025-04-05T18:04:11.896092Z","shell.execute_reply.started":"2025-04-05T18:04:09.413649Z","shell.execute_reply":"2025-04-05T18:04:11.894913Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import torch\nfrom torch import nn\ntorch.manual_seed(123)\nfrom torch.utils.data import ConcatDataset\n# import torch_xla\n# import torch_xla.core.xla_model as xm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T18:04:11.897248Z","iopub.execute_input":"2025-04-05T18:04:11.897758Z","iopub.status.idle":"2025-04-05T18:04:15.724652Z","shell.execute_reply.started":"2025-04-05T18:04:11.897719Z","shell.execute_reply":"2025-04-05T18:04:15.723635Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import os \nimport sys\nos.environ[\"CUDA_LAUNCH_BLOCKING\"]=\"1\" ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T18:04:15.725571Z","iopub.execute_input":"2025-04-05T18:04:15.726155Z","iopub.status.idle":"2025-04-05T18:04:15.730665Z","shell.execute_reply.started":"2025-04-05T18:04:15.726104Z","shell.execute_reply":"2025-04-05T18:04:15.729588Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"### Model and Data Path","metadata":{}},{"cell_type":"code","source":"# enter model path\nsys.path.append(\"/kaggle/input/ohlc_daily_gpt/pytorch/default/1\")\n\n# enter datapath\nsys.path.append(\"/kaggle/input/all-stock-data\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T18:04:15.731675Z","iopub.execute_input":"2025-04-05T18:04:15.731991Z","iopub.status.idle":"2025-04-05T18:04:15.752429Z","shell.execute_reply.started":"2025-04-05T18:04:15.731965Z","shell.execute_reply":"2025-04-05T18:04:15.751404Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from ohlcv_tokenizer import OHLCV_Tokenizer, OHLCV_Vocab\nfrom ohlcv_data_cleaner_assembler import OHLCV_DataCleanerAssembler","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T18:04:15.753527Z","iopub.execute_input":"2025-04-05T18:04:15.753864Z","iopub.status.idle":"2025-04-05T18:04:15.784409Z","shell.execute_reply.started":"2025-04-05T18:04:15.753836Z","shell.execute_reply":"2025-04-05T18:04:15.783506Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"from stock_tokenizer import (\ncreate_data_loader_for_stock, create_data_loader_for_tokenizer\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T18:04:15.787632Z","iopub.execute_input":"2025-04-05T18:04:15.787911Z","iopub.status.idle":"2025-04-05T18:04:15.799185Z","shell.execute_reply.started":"2025-04-05T18:04:15.787888Z","shell.execute_reply":"2025-04-05T18:04:15.798183Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"from gpt_config import GPT_CONFIG, set_gpt_config_param\nset_gpt_config_param(\"stock_path\",\n                    \"/kaggle/input/all-stock-data/\")\nstock_path = GPT_CONFIG[\"stock_path\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T18:04:15.800959Z","iopub.execute_input":"2025-04-05T18:04:15.801376Z","iopub.status.idle":"2025-04-05T18:04:15.810553Z","shell.execute_reply.started":"2025-04-05T18:04:15.801338Z","shell.execute_reply":"2025-04-05T18:04:15.809483Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"set_gpt_config_param(\"save_checkpoint_step\", 1000)\nset_gpt_config_param(\"max_vocab\", 20_000)\n# set_gpt_config_param(\"rolling_window\", 20)\nset_gpt_config_param(\"save_path\",\"/kaggle/working/\")\nset_gpt_config_param(\"vocab_size\", 20_000 + 1) # hard coded \nset_gpt_config_param(\"emb_dim\", 256)\nset_gpt_config_param(\"n_layers\", 6)\nset_gpt_config_param(\"input_batch_size\", 256)\nset_gpt_config_param(\"target_batch_size\", 1)\nset_gpt_config_param(\"batch_size\", 5)\nGPT_CONFIG","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T18:04:15.811699Z","iopub.execute_input":"2025-04-05T18:04:15.812074Z","iopub.status.idle":"2025-04-05T18:04:15.828300Z","shell.execute_reply.started":"2025-04-05T18:04:15.812048Z","shell.execute_reply":"2025-04-05T18:04:15.827289Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"{'stock_path': '/kaggle/input/all-stock-data/',\n 'min_bin': -10000,\n 'max_bin': 10000,\n 'min_vocab': 0,\n 'max_vocab': 20000,\n 'bin_size': 50,\n 'batch_size': 5,\n 'stride': 4,\n 'multiply_by': 10000.0,\n 'context_length': 256,\n 'emb_dim': 256,\n 'n_heads': 4,\n 'n_layers': 6,\n 'dropout_rate': 0.05,\n 'qkv_bias': False,\n 'predict_new_tokens': 1,\n 'train_ratio': 0.9,\n 'num_epochs': 1,\n 'adamw_learning_rate': 0.0004,\n 'adamw_weight_decay': 0.1,\n 'save_checkpoint_step': 1000,\n 'save_path': '/kaggle/working/',\n 'temperature': 1,\n 'topk': 7,\n 'vocab_size': 20001,\n 'input_batch_size': 256,\n 'target_batch_size': 1}"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"# mca = MonthDataCleanerAssembler(\n#     cfg = GPT_CONFIG,\n#     stock_path=stock_path, \n#     is_batch=True,\n#     is_return=False\n# )\n\ndef func_concat_dataset(folder_name):\n    total_concat_dataset = []\n    for f in os.listdir(folder_name):\n        print(f)\n        total_concat_dataset.append( # if monthly, use MonthDataCleanerAssembler\n            OHLCV_DataCleanerAssembler(\n                cfg = GPT_CONFIG,\n                stock_path=os.path.join(stock_path, folder_name, f), # change this \n                is_batch=True,\n            ).ConcatDataset()\n        )\n    return total_concat_dataset\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T18:04:15.829306Z","iopub.execute_input":"2025-04-05T18:04:15.829598Z","iopub.status.idle":"2025-04-05T18:04:15.843336Z","shell.execute_reply.started":"2025-04-05T18:04:15.829575Z","shell.execute_reply":"2025-04-05T18:04:15.842284Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"### Create Dataloader for training\n\n    1.abc folder \n\n    2. defgh folder\n\n    3. ijklmn folder\n    \n    4. opqrst folder \n\n    5. uvwxyz folder ","metadata":{}},{"cell_type":"code","source":"all_datasets = func_concat_dataset(\"/kaggle/input/all-stock-data/abc\")\ntrain_loader = create_data_loader_for_tokenizer(\n    ConcatDataset(all_datasets),\n    cfg = GPT_CONFIG,\n    batch_size=GPT_CONFIG[\"batch_size\"],\n    shuffle = True,\n    num_workers=4 \n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T18:04:15.844203Z","iopub.execute_input":"2025-04-05T18:04:15.844501Z","iopub.status.idle":"2025-04-05T18:07:25.146292Z","shell.execute_reply.started":"2025-04-05T18:04:15.844478Z","shell.execute_reply":"2025-04-05T18:07:25.145348Z"}},"outputs":[{"name":"stdout","text":"b\na\nUnexpected error in file /kaggle/input/all-stock-data/abc/a/amrhw.us.txt, error err=EmptyDataError('No columns to parse from file'), type(err)=<class 'pandas.errors.EmptyDataError'>\nUnexpected error in file /kaggle/input/all-stock-data/abc/a/amrh.us.txt, error err=EmptyDataError('No columns to parse from file'), type(err)=<class 'pandas.errors.EmptyDataError'>\nUnexpected error in file /kaggle/input/all-stock-data/abc/a/asns.us.txt, error err=EmptyDataError('No columns to parse from file'), type(err)=<class 'pandas.errors.EmptyDataError'>\nc\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"#### Custom Validation Loader for evaluation","metadata":{}},{"cell_type":"code","source":"_interested_stock = \"/kaggle/input/all-stock-data/opqrst/r\"\n\n_interested_stock = OHLCV_DataCleanerAssembler(\n    cfg = GPT_CONFIG, stock_path=_interested_stock,\n    is_batch = True,\n)\n\n# debug -- remove after debug \n# train_loader = create_data_loader_for_tokenizer(\n#     _interested_stock.ConcatDataset(), \n#     GPT_CONFIG,\n#     batch_size=GPT_CONFIG[\"batch_size\"],\n#     num_workers=4, \n#     shuffle=True \n# )\n\ncustom_val_loader = create_data_loader_for_tokenizer(\n    _interested_stock.ConcatDataset(), \n    GPT_CONFIG,\n    batch_size=GPT_CONFIG[\"batch_size\"],\n    num_workers=4, \n    shuffle=True \n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T18:07:25.147370Z","iopub.execute_input":"2025-04-05T18:07:25.147753Z","iopub.status.idle":"2025-04-05T18:07:50.413298Z","shell.execute_reply.started":"2025-04-05T18:07:25.147717Z","shell.execute_reply":"2025-04-05T18:07:50.412452Z"}},"outputs":[{"name":"stdout","text":"Unexpected error in file /kaggle/input/all-stock-data/opqrst/r/rbio.us.txt, error err=EmptyDataError('No columns to parse from file'), type(err)=<class 'pandas.errors.EmptyDataError'>\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"### GPT Model, Parallelization and device","metadata":{}},{"cell_type":"code","source":"from ohlcv_gpt_model import OHLCV_GPTModel \nfrom data_parallel import data_parallel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T18:07:50.414325Z","iopub.execute_input":"2025-04-05T18:07:50.414683Z","iopub.status.idle":"2025-04-05T18:07:50.443059Z","shell.execute_reply.started":"2025-04-05T18:07:50.414648Z","shell.execute_reply":"2025-04-05T18:07:50.442270Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"gpt_model = OHLCV_GPTModel(\n    cfg=GPT_CONFIG,\n    n_cols = 4\n)\n\n# if xm.xla_device().type == \"xla\":\n#     print(\"using tpu\")\n#     device = xm.xla_device()\n#     gpt_model = gpt_model.to(device)\n# else:\n\ngpt_model, device = data_parallel(gpt_model)\n\nprint(sum(p.numel() for p in gpt_model.parameters()))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T18:07:50.443991Z","iopub.execute_input":"2025-04-05T18:07:50.444320Z","iopub.status.idle":"2025-04-05T18:07:50.670084Z","shell.execute_reply.started":"2025-04-05T18:07:50.444293Z","shell.execute_reply":"2025-04-05T18:07:50.669070Z"}},"outputs":[{"name":"stdout","text":"Using CPU\n16083200\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"### Model Training","metadata":{}},{"cell_type":"code","source":"from stock_train_mechanism import StockTrainer \n\ntrainer = StockTrainer(\n    model = gpt_model,\n    cfg = GPT_CONFIG,\n    load_from_checkpoint=None,\n    device = device.type # \"cuda\" or \"cpu\"\n)\n\nprint(trainer)\n# see if this uses 2 GPUs or 1 GPU ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T18:07:50.671100Z","iopub.execute_input":"2025-04-05T18:07:50.671395Z","iopub.status.idle":"2025-04-05T18:07:53.032952Z","shell.execute_reply.started":"2025-04-05T18:07:50.671371Z","shell.execute_reply":"2025-04-05T18:07:53.031960Z"}},"outputs":[{"name":"stdout","text":"\n        ============================================================\n            Training Statistics for this exercise >>> \n\n            Device : cpu\n            Total Epochs trained : 0\n            Total Steps trained : 0\n            Total number of tokens seen so far : 0\n            Training Loss : []\n            Validation Loss : []\n        ============================================================\n        \n        \n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"trainer.engage_training(train_loader=train_loader,\n                       num_epochs=1,\n                       val_loader=custom_val_loader,\n                       eval_freq=100,\n                        eval_iter=5\n                       )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T18:07:53.033887Z","iopub.execute_input":"2025-04-05T18:07:53.034410Z","iopub.status.idle":"2025-04-05T18:07:54.313539Z","shell.execute_reply.started":"2025-04-05T18:07:53.034370Z","shell.execute_reply":"2025-04-05T18:07:54.311939Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-6a05067137fa>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m trainer.engage_training(train_loader=train_loader,\n\u001b[0m\u001b[1;32m      2\u001b[0m                        \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                        \u001b[0mval_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_val_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                        \u001b[0meval_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                         \u001b[0meval_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/input/ohlc_daily_gpt/pytorch/default/1/stock_train_mechanism.py\u001b[0m in \u001b[0;36mengage_training\u001b[0;34m(self, train_loader, num_epochs, val_loader, eval_freq, eval_iter)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m                 loss = calc_loss_batch(\n\u001b[0m\u001b[1;32m     99\u001b[0m                     \u001b[0minput_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 )\n","\u001b[0;32m/kaggle/input/ohlc_daily_gpt/pytorch/default/1/stock_loss_prediction.py\u001b[0m in \u001b[0;36mcalc_loss_batch\u001b[0;34m(input_batch, target_batch, model)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mtarget_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     loss = torch.nn.functional.cross_entropy(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/input/ohlc_daily_gpt/pytorch/default/1/ohlcv_gpt_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_tensor)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mtok_embedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0mtok_embedded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtok_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpos_embeds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mtok_embedded\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtok_embedded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mtotal_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombiner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtok_embedded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    191\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2549\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2550\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: index out of range in self"],"ename":"IndexError","evalue":"index out of range in self","output_type":"error"}],"execution_count":15},{"cell_type":"code","source":"trainer.plot_losses()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T18:07:54.314354Z","iopub.status.idle":"2025-04-05T18:07:54.314696Z","shell.execute_reply":"2025-04-05T18:07:54.314557Z"}},"outputs":[],"execution_count":null}]}